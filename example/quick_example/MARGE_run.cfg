# Configuration files for MARGE use the format for Python's configparser package
# In practice, this means that sections are defined like
# [Section name]
# followed by any parameters for that section.  The [DEFAULT] section is special 
# and sets the default parameters for all other sections.
# Users can leverage this to train and evaluate multiple models by setting up 
# multiple sections, where each section changes only the parameters that are 
# different between each run, with the DEFAULT section holding the parameters 
# that are common to all runs.
# Note that you MUST specify at least 1 sections that is not DEFAULT.
# Parameter ordering does not matter.
# All parameters are specified as <key> = <value>.  Note that <value> is 
# generally a specific format; use these files as examples to follow.  
# See the User Manual for additional details.

[DEFAULT]
# Place parameters here that will remain the same for all other sections

# Determines whether to resume a previous run
# Note that it does not resume from exactly the same state, so the first 
# epoch will generally result in an increase in loss, but the model will quickly
# achieve a loss lower than the previous run
resume = False

# Sets a random seed.  Currently, it is not used within the code.
seed = 0

# Sets the verbosity of logging, that is, how much text is output.
# 0: Only output errors and critical messages
# 1: The above, plus warnings
# 2: The above, plus important details
# 3: The above, plus a little extra detail
# 4: The above, plus a list of all default parameters assumed if they were not 
#    specified in the configuration file
# 5: Maximum detail
# Levels 2-4 are recommended for most uses.  5 is useful when investigating
# unexpected behavior.  Note that even on level 0, there is still some output
# printed to the screen
verb = 2

[MARGE]
# This is a section that will be executed by MARGE.  Any parameters not 
# specified here will default to what is set in DEFAULTS, and if it is not 
# specified there then it will use the default set within MARGE

# Determines whether to use MARGE's data generation feature.  Note that you 
# must code up your own function to utilize this.
datagen = False

# If `datagen` is True, this sets the file name that holds your 
# custom function for data generation
datagenfile = datagen

# If `datagen` is True, this allows the user to pass through a configuration 
# file to the `datagen` function, if needed by their code.  For example, this 
# is used to pass through a BART configuration file for data generation.
cfile = None

# Determines whether to use MARGE's data processing feature, which is used to 
# format the data into MARGE's required format.  Note that you must code up 
# your own function to utilize this.
processdat = False

# If `processdat` is True, this parameter controls whether to preserve the 
# original data or not.  It is recommended that this always remains True, 
# unless you have a very large data set and do not have sufficient space to 
# duplicate the data.
preservedat = True

# These booleans determine 
NNModel   = True  # will you use a neural network
trainflag = True  # will you train the model
validflag = True  # will you validate the model
testflag  = False # will you test the model

# These parameters are used for a Bayesian hyperparameter optimization.
# Here, we are not using them, as `optimize = 0` disables this feature.
# For details on these parameters, look at MARGE_optimization.cfg
optimize = 0
optngpus = 4
optnlays = 1 3
optlayer = dense dense dense
optnnode = 2 4 8 16 32 64 128 256
optmaxconvnode = 256
optactiv = relu elu leakyrelu sig tanh
optactrng = 0.01 0.6
optminlr = None
optmaxlr = None

# This parameter sets a prefix for the TFRecords files that the data are 
# processed into for efficiency when running MARGE
TFR_file = circle

# Sets the number of batches to pre-load into memory
buffer = 15

# Sets the number of CPU cores to use to pre-load batches in parallel
ncores = 6

# Determines whether to normalize the data, that is, subtract the mean and 
# divide by the standard deviation
normalize = False

# Determines whether to scale the data to the range specified by `scalelims` 
# based on the extrema
scale     = True
scalelims = -1, 1

# Sets directories that will be used by MARGE
inputdir  = inputs_quickexample # Inputs will go here. Statistics about the data set, TFRecords files
outputdir = outputs_run # Outputs will go here. Model weights file, predictions on validation and/or test data, R2 and RMSE results, plots
plotdir   = plots # Where to store the plots.  For relative paths, it is relative to `outputdir`
datadir   = ../data # Where your .NPZ data files are located
preddir   = pred # Where to store the predictions.  For relative paths, it is relative to `outputdir`

# Sets the shapes of the data set's inputs and outputs
# For 2D data, it would be formatted like, e.g., "3,10" for a 3x10 array.
ishape = 1 # Input  data shape
oshape = 2 # Output data shape

# Determines whether to base-10 logarithmically transform the data.
# If True, performs this for all indices
# To only perform this for specific indices, provide them as space-separated values, starting from 0
# E.g., to log-transform the 0th and 3rd indices of the inputs, do 
#       ilog = 0 3
ilog = False # Input  data log transformation
olog = False # Output data log transformation

# Used when plotting RMSE, R2, and specific cases
xvals = None # X-axis values when plotting.  For example, this might be a wavelength grid, if your outputs are spectra at pre-determined wavelengths
xlabel = None # X-axis label.  You can do some LaTeX-like things, e.g., $cm^{-1}$ to make the "-1" superscript, or H$_2$O to make the "2" a subscript.
ylabel = None # Y-axis label

# Determines over which axes to compute the data statistics.
# all = all axes except the very last (e.g., if you have radiances, temperature, pressure as the last axis, they will be calculated independently)
# batch = only over the batch axis (e.g., if you have image data and wish to calculate the statistics per pixel)
statsaxes = all

# Data statistics file names.  If a relative path, assumed to be relative to `inputdir`
fxmean = xmean.npy  # Mean of input  data, per-parameter along the last axis
fymean = ymean.npy  # Mean of output data
fxstd = xstd.npy    # Standard deviation of input  data
fystd = ystd.npy    # Standard deviation of output data
fxmin = xmin.npy    # Minima of the input  data
fxmax = xmax.npy    # Maxima of the input  data
fymin = ymin.npy    # Minima of the output data
fymax = ymax.npy    # Maxima of the output data
fsize = datsize.npy # Size of the training, validation, and test sets

# Prediction statistics file names.  If a relative path, assumed to be relative to `outputdir`
rmse_file = rmse
r2_file = r2

# The Keras model weights file.  MUST end in .keras.
weight_file = nn_weights.keras

# Determines whether to perform a grid search.  See the User Manual for more details.
gridsearch = False

# Sets the number of nodes per layer that has nodes.  Space-separated values.
nodes = 64 256 16

# Sets the activation function per layer that has nodes. Space separated.
activations = relu elu sig

# Sets the parameter for each activation function
# For activation functions that do not have a parameter, or to use the default, 
# use None.  Space separated.
act_params =  None 0.05585 None

# Sets the type of each hidden layer.  Space separated.
layers = dense dense dense

# Sets the parameter for each hidden layer.  For layers that do not have free 
# parameters, or to use the default, use None.  Space separated.
lay_params = None None None

# Set the number of iterations through the data set to consider
epochs     = 3000

# Set the early stopping criteria.  If there is no improvement after `patience` 
# epochs, then terminate training.  Here, since it is set higher than the 
# number of epochs, early stopping will never engage.
patience   = 60

# Set the batch size, or number of data cases to use in each iteration.
batch_size = 256

# Set the minimum and maximum learning rate
lengthscale = 1e-3 # This parameter can also be called `min_lr`
max_lr      = 1e-1

# Sets the cyclical learning rate mode and how long each cycle is.
# For more details, see the User Manual.
clr_mode  = triangular2
clr_steps = 6

# Determines which test cases to plot.  Use integers to specify the index in the 
# test set to plot.  Space or new-line separated.  Use None to not plot any.
# Note that plotting only works for 1D output data.
plot_cases = None

# Determines the window size for a Svitsky-Golay filter in the output plots
# Can be useful for high resolution spectra to better see trends in differences 
# between predicted and true spectra.
smoothing  = 0
